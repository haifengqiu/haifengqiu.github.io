<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="atom.xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://haifengqiu.github.io/blog</id>
    <title>梓宏工坊 Blog</title>
    <updated>2024-11-21T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://haifengqiu.github.io/blog"/>
    <subtitle>梓宏工坊 Blog</subtitle>
    <icon>https://haifengqiu.github.io/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[2024-11-21-crewai & Dify试用]]></title>
        <id>https://haifengqiu.github.io/blog/crewai&amp;dify</id>
        <link href="https://haifengqiu.github.io/blog/crewai&amp;dify"/>
        <updated>2024-11-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[为了实现一个智能客服系统，对crewai和Dify进行了试用。]]></summary>
        <content type="html"><![CDATA[<p>为了实现一个智能客服系统，对crewai和Dify进行了试用。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="背景">背景<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E8%83%8C%E6%99%AF" class="hash-link" aria-label="背景的直接链接" title="背景的直接链接">​</a></h2>
<p>业务背景：实现一个私有化部署、有私域知识、多模态支持、多渠道接入的智能客服系统。这里以Crew AI和Dify作为两大类开源可商用的技术路线代表进行比较。</p>
<p>Crew AI是标准的、支持多智能体协同的工具。类似的还有微软的autogen、Open AI的swarm、LangChain的LangGraph等。以crewai作为代表，是因为它更成熟、功能更全面、案例更多。</p>
<p>Dify更多的是一个LLMOps框架、大模型应用开发平台。类似的开源框架有fastgpt，商业产品有字节的coze。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="简述">简述<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E7%AE%80%E8%BF%B0" class="hash-link" aria-label="简述的直接链接" title="简述的直接链接">​</a></h2>
<p>本文输出的结论仅为初学者未调优、本地体验所得，存在主观看法，未必正确，仅供参考。</p>
<p>Dify/fastgpt已有的功能更适合实现一个智能客服，可以快速地实现一个MVP版本（尽管交付给用户的界面是重写。Dify自带的界面用来做设计态或者内部运维界面也是实用的），而需要改进的点也可以较方便地替换成自己的组件和实现。在易用性、响应速度、稳定性等方面相比Crew AI也更有优势。Crew AI能快速跑起来示例，但响应时间相对更慢，而且多轮重复运行后出现了预计外的错误（提示词指定了使用中文回答，前几轮循环正常，后面就变成英文答案和LLM异常了。27b的GEMMA和72b的QWEN都会出现，GPU是足够的）。</p>
<p>LLMOps类的框架，在ops这块确实更易用更全面。这里的ops含义从DevOps中的运维扩展到运营，体现在可视化的调试、监控、日志、发布、token计费等方面，更容易对整个项目方案有更多的信息收集和掌控。反过来crewai的调试、监测等是需要通过命令行和编程去实现，更灵活，但那是在一定时间和工作量之后。</p>
<p>PS：在体验Crew AI过程中查阅官方和网络上的示例，几乎都不是智能客服这种（尤其是电话客服）实时性、互动性要求高的应用，更多是订票、写博文、预定会议等。这个也是更快转向Dify的一个原因，Dify有聊天助手的应用类型，而且有多个客服相关的应用模版。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="agent支持度">agent支持度<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#agent%E6%94%AF%E6%8C%81%E5%BA%A6" class="hash-link" aria-label="agent支持度的直接链接" title="agent支持度的直接链接">​</a></h2>
<p>agent的定义和分类很多，这里使用相对最普遍的定义：agent=llm+memory+tool+plan。</p>
<p>Crew AI对这些概念不仅是支持的，而且有对应的逻辑实体和api来对应，整个agent的实现风格就是指定LLM，配置memory选项，指定agent使用的工具集，声明agent扮演什么角色完成哪些任务，声明整个crew团体的组织结构和代理委派的模式。而这些声明式的代码编写完成，应用代码就几乎完成了。</p>
<p>在memory这块不仅支持短期记忆和长期记忆，还支持实体内存，可以捕获运行期遇到的实体概念，从而促进更深入的理解和关系映射。</p>
<p>Crew AI建立在Langchain 之上，可以访问他们的所有工具,同时自身也提供了一套工具集。用户还可以定义和集成针对其特定需求量身定制的工具。</p>
<p>多智能体协同：Crew AI 支持灵活的任务管理、自主的代理间委派。</p>
<p>而Dify这边，尽管有单独的agent的应用类型，agent可指定知识库和工具，但多个智能体之间的协同机制是没有的需要自行实现。如果是创建工作流类型的应用，可以引入多个处理LLM/知识检索/工具节点进行协作，而非多agent的协作。此外，Dify只有聊天记录的内置记忆和编排变量的机制。至于工具内置、扩展和生态方面，Dify也有相关的能力。工具并不是最核心的差异。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm接入">LLM接入<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#llm%E6%8E%A5%E5%85%A5" class="hash-link" aria-label="LLM接入的直接链接" title="LLM接入的直接链接">​</a></h2>
<p>区别不大，主流LLM服务和本地LLM都能支持。如果某些本地LLM部署框架不支持，也可以通过one api这种，代理本地LLM模型服务伪装成openai接口即可。而openai接口各框架都支持，甚至是默认选项。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rag支持度">RAG支持度<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#rag%E6%94%AF%E6%8C%81%E5%BA%A6" class="hash-link" aria-label="RAG支持度的直接链接" title="RAG支持度的直接链接">​</a></h2>
<p>Crew AI并没有强调RAG，只是提供了一系列的RAG Tool。而这些单独的rag并不能在实践中独立、容易完成私域知识检索的能力。而Dify有单独的知识库管理，有单独的知识检索类型的节点，支持配置嵌入模型和多种检索模式等，能够快速而完整地将私域知识纳管和用于应用中。而Crew AI需要达到该目标，按官方的倾向应该是集成LangIndex使用。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="本地开发学习曲线">本地开发学习曲线<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E6%9C%AC%E5%9C%B0%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF" class="hash-link" aria-label="本地开发学习曲线的直接链接" title="本地开发学习曲线的直接链接">​</a></h2>
<p>本地安装部署这块都比较顺利和简单，运行简单的示例都不难，相对而言，Crew AI会差一点，因为命令行示例并没有第一次成功（python代码首次是成功的），更何况Dify是提供了精美页面和示例应用模板的。</p>
<p>接下来是希望找到更合适我们的示例模版，跑起来，然后再修改，而非从头开始。在这点上，Dify提供了国内外大量的应用模板，而且如前文所述有复数客服相关模板。而且基于模板创建应用后，是可以快速跑起来的，包括每一步的输入输出和性能，不用专门学习都能在界面上找到。小的修改也是可以基于页面的工作流、代码节点、http调用节点和丰富的工具市场来完成。这种小步快跑、即时反馈的风格，更适合初学者。而Crew AI的代码灵活度更高，全代码受控，更适合熟练者有代码控制和完成业务应用。在Dify能支持的灵活度范围内，基于界面、工作流和丰富模板的方式更易上手和更易验证业务目标。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="开放与集成">开放与集成<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E5%BC%80%E6%94%BE%E4%B8%8E%E9%9B%86%E6%88%90" class="hash-link" aria-label="开放与集成的直接链接" title="开放与集成的直接链接">​</a></h2>
<p>对于Crew AI，整个应用代码都是自己写的，开放与集成自然是可以任意和完全控制的，但同样需要自行实现的成本。所以本节主要描述Dify在这块的表现。</p>
<p>开放api。Dify搭建出的应用是非常容易发布成直接可用的站点，或者嵌入到自己的业务系统，也提供了http api和sdk来再开发。PS：提供的http的对话接口是支持流式和中断的。</p>
<p>代码执行。工作流节点类型中有代码执行节点。支持python和nodejs代码。</p>
<p>用户输入/人机交互。在Dify中使用用户输入或者反求用户补充信息，基于对话和变量都是容易配置的。</p>
<p>内置的语音输入和语音播报，同样是可以换成自有实现版本。Dify和fastgpt这种平台更多是胶水和脚手架，本身并没有包括和限定哪种模型。哪怕官方没有说明支持本地的哪种模型，也可以通过代理成官方支持模型的api来实现接入和替换。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="性能">性能<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E6%80%A7%E8%83%BD" class="hash-link" aria-label="性能的直接链接" title="性能的直接链接">​</a></h2>
<p>在8卡4090的服务器上通过docker部署Dify和Ollama，通过Ollama部署qwen2.5:72b和gemma2:27b和mxbai-embed-large，8卡显存占用13G左右。</p>
<p>应用使用的LLM是qwen72b时，LLM开始出字在3-4s，生成token在60token/s左右。
同样的应用，LLM换成gemma27b时，LLM开始出字在1s，生成token在300token/s左右。两者都回答质量差不多，更多取决于知识检索的准确率，但gemma生成的回答更简略些。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="多模态支持">多模态支持<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%94%AF%E6%8C%81" class="hash-link" aria-label="多模态支持的直接链接" title="多模态支持的直接链接">​</a></h2>
<p>Dify默认支持语音输入和语音播报。</p>
<p>在对话过程中支持用户上传文件，配备文档提取器将文档解析为文本供 LLM 理解。</p>
<p>对于音频文件，可以使用 gpt-4o-audio-preview 等支持多模态输入的模型直接处理音频，无需额外的提取器。</p>
<p>对于视频和其他文件类型，暂无对应的提取器，需要应用开发者接入外部工具进行处理。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="持续改进">持续改进<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E6%8C%81%E7%BB%AD%E6%94%B9%E8%BF%9B" class="hash-link" aria-label="持续改进的直接链接" title="持续改进的直接链接">​</a></h2>
<p>首先两者都有单步重放、单步调试的能力，来确认新配置/新模型/新数据的改进效果。而Dify的持续改进优势更多在数据上，在知识库的管理上，可以人工标注、召回测试等。而Crew AI的持续改进优势更多在agent能力上，提供了基于命令行和编程方式的训练agent的机制。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="其他">其他<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E5%85%B6%E4%BB%96" class="hash-link" aria-label="其他的直接链接" title="其他的直接链接">​</a></h2>
<p>基于agent去实现客服理论上是适合的，但受限于LLM和agent目前的能力，在落地时还是有不少问题的，不仅只是rag准确度的问题。可以参考<a href="https://www.zhihu.com/question/624354739" target="_blank" rel="noopener noreferrer">知乎上的这篇回答</a>。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="参考资料">参考资料<a href="https://haifengqiu.github.io/blog/crewai&amp;dify#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99" class="hash-link" aria-label="参考资料的直接链接" title="参考资料的直接链接">​</a></h2>
<p><a href="https://www.galileo.ai/blog/mastering-agents-langgraph-vs-autogen-vs-crew" target="_blank" rel="noopener noreferrer">LangGraph VS Autogen VS Crew AI</a></p>]]></content>
        <author>
            <name>梓宏</name>
            <uri>https://github.com/haifengqiu</uri>
        </author>
        <category label="agent" term="agent"/>
        <category label="dify" term="dify"/>
        <category label="crewai" term="crewai"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[2024-10-09-基于sherpa的本地智能语音助手入门-Java Api版]]></title>
        <id>https://haifengqiu.github.io/blog/sherpa-java-quickstart</id>
        <link href="https://haifengqiu.github.io/blog/sherpa-java-quickstart"/>
        <updated>2024-10-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[sherpa是新一代Kaldi的部署框架。这里使用sherpa-onnx来实现一个本地智能语音助手。]]></summary>
        <content type="html"><![CDATA[<p>sherpa是新一代Kaldi的部署框架。这里使用sherpa-onnx来实现一个本地智能语音助手。</p>
<p>它将支持流式的关键词唤醒和语音识别、文本转语音、热词等，且整个过程中无需互联网，可以没有GPU，适合部署在边缘侧/用户侧设备上。</p>
<p>考虑到java开发者和基于java的应用系统更为广泛，撰写此文，也为sherpa社区做一点微薄贡献。感谢sherpa开源社区。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="写在前面">写在前面<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2" class="hash-link" aria-label="写在前面的直接链接" title="写在前面的直接链接">​</a></h2>
<p>为何使用sherpa？因为我们的项目需要支持本地的、实时音频流处理，且性能较好的情况下硬件资源要求尽量低一些。而sherpa提供了工程化程度高的、不依赖特定模型的、完整的语音识别解决方案，且性能表现优异（可以使用低配置的设备在浏览器中访问<a href="https://k2-fsa.github.io/sherpa/huggingface/index.html" target="_blank" rel="noopener noreferrer">官方示例</a>先体验效果和性能）。</p>
<p>为何使用sherpa-onnx？从官方的<a href="https://k2-fsa.github.io/sherpa/intro.html" target="_blank" rel="noopener noreferrer">https://k2-fsa.github.io/sherpa/intro.html</a> 中可以看到sherpa-onnx在平台、语言、特定子领域/特性的支持度是最全面的。</p>
<p>为何使用java api？除开简介中的因素外，java少了一些安装、依赖库冲突等问题（根据本人这种python新手在windows/ubuntu下安装和使用python api的感受，尽管成功但路径不一样，且坎坷都不一样），即java环境反而是最容易搭建成功的，对于java从业者也更容易根据调试信息来猜测api和数据用法。当然，其示例丰富度和官方支持度相比c++/python是有明显差距的。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="基础概念">基础概念<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5" class="hash-link" aria-label="基础概念的直接链接" title="基础概念的直接链接">​</a></h2>
<p>受限于本人技术能力，本篇介绍的概念/方法/用途不一定正确，且假设读者已经了解基本的java编程和语音识别基础理论。</p>
<p>sherpa-onnx社区提供了预训练的模型，以及多语言的Api文档和示例代码，其中支持度最好的是c++和python。对于使用java api来构建我们的项目，需要理解我们的项目是<em><strong>通过jni来调用sherpa-onnx的动态库来使用已经预训练好的相关语音模型</strong></em>，来实现语音相关功能。并不需要安装sherpa-onnx、训练模型等。换言之，在正常普通的java项目开发的基础上，了解和学习jni的基础知识是必须的，而java的平台无关性此时会受到sherpa-onnx动态库的影响，在不同的平台上应换用不同的动态库。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="准备环境">准备环境<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#%E5%87%86%E5%A4%87%E7%8E%AF%E5%A2%83" class="hash-link" aria-label="准备环境的直接链接" title="准备环境的直接链接">​</a></h2>
<p>java环境、jdk、maven等这些基础知识不再介绍。</p>
<p>sherpa-onnx的<a href="https://k2-fsa.github.io/sherpa/onnx/index.html" target="_blank" rel="noopener noreferrer">官方文档</a>写的比较清楚，章节导航和内容长度也比较合理，建议先学习官方文档。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sherpa-onnx的动态库获取">sherpa-onnx的动态库获取<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#sherpa-onnx%E7%9A%84%E5%8A%A8%E6%80%81%E5%BA%93%E8%8E%B7%E5%8F%96" class="hash-link" aria-label="sherpa-onnx的动态库获取的直接链接" title="sherpa-onnx的动态库获取的直接链接">​</a></h3>
<p>以下内容<a href="https://k2-fsa.github.io/sherpa/onnx/java-api/index.html" target="_blank" rel="noopener noreferrer">官方文档对应章节</a>中也已描述的清楚，这里只进行补充。
首先注意动态库是区分平台的，需要根据部署设备的架构和操作系统来选择。
其次动态库可以选择下载官方提供的，也可以自己构建。建议选择前者，前者不满足时再考虑后者（需要搭建c++编译环境）。</p>
<p>这里稍微注意下，windows下自行构建jni的教程在：<a href="https://github.com/k2-fsa/sherpa-onnx/issues/882" target="_blank" rel="noopener noreferrer">https://github.com/k2-fsa/sherpa-onnx/issues/882</a> 。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sherpa-onnx的预训练模型下载">sherpa-onnx的预训练模型下载<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#sherpa-onnx%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD" class="hash-link" aria-label="sherpa-onnx的预训练模型下载的直接链接" title="sherpa-onnx的预训练模型下载的直接链接">​</a></h3>
<p>可以在不同章节（如ASR/TTS/Keyword spotting的对应官方文档章节）里找对应的模型下载，也可以在<a href="https://k2-fsa.github.io/sherpa/onnx/pretrained_models/index.html" target="_blank" rel="noopener noreferrer">https://k2-fsa.github.io/sherpa/onnx/pretrained_models/index.html</a> 这里统一查看。</p>
<p>这里列举下本人项目中目前使用的模型：</p>
<ol>
<li>关键词检测：<a href="https://k2-fsa.github.io/sherpa/onnx/kws/pretrained_models/index.html#sherpa-onnx-kws-zipformer-wenetspeech-3-3m-2024-01-01-chinese" target="_blank" rel="noopener noreferrer">https://k2-fsa.github.io/sherpa/onnx/kws/pretrained_models/index.html#sherpa-onnx-kws-zipformer-wenetspeech-3-3m-2024-01-01-chinese</a></li>
<li>ASR：<a href="https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english" target="_blank" rel="noopener noreferrer">https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english</a></li>
<li>TTS： <a href="https://k2-fsa.github.io/sherpa/onnx/tts/pretrained_models/vits.html#aishell3-chinese-multi-speaker-174-speakers" target="_blank" rel="noopener noreferrer">https://k2-fsa.github.io/sherpa/onnx/tts/pretrained_models/vits.html#aishell3-chinese-multi-speaker-174-speakers</a></li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sherpa-onnx的java-api库及示例获取">sherpa-onnx的java api库及示例获取<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#sherpa-onnx%E7%9A%84java-api%E5%BA%93%E5%8F%8A%E7%A4%BA%E4%BE%8B%E8%8E%B7%E5%8F%96" class="hash-link" aria-label="sherpa-onnx的java api库及示例获取的直接链接" title="sherpa-onnx的java api库及示例获取的直接链接">​</a></h3>
<p>java api见<a href="https://k2-fsa.github.io/sherpa/onnx/java-api/build-jar.html" target="_blank" rel="noopener noreferrer">官方文档章节</a>。我这边是将源码拷到项目中，方便调试和修改。java api的源码复杂度不高，没有过度封装和抽象。</p>
<p>java调用的示例代码在上述章节中也提到了，但确实数量较少。需要发挥一下主观能动性和大模型的能力，对比联想+连猜带蒙。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="构建项目">构建项目<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#%E6%9E%84%E5%BB%BA%E9%A1%B9%E7%9B%AE" class="hash-link" aria-label="构建项目的直接链接" title="构建项目的直接链接">​</a></h2>
<p>java项目的基础结构这里不赘述。可以参考 <a href="https://github.com/haifengqiu/sherpa-onnx-java-demo/tree/main" target="_blank" rel="noopener noreferrer">https://github.com/haifengqiu/sherpa-onnx-java-demo/tree/main</a> 。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="jni相关的vm配置">jni相关的vm配置<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#jni%E7%9B%B8%E5%85%B3%E7%9A%84vm%E9%85%8D%E7%BD%AE" class="hash-link" aria-label="jni相关的vm配置的直接链接" title="jni相关的vm配置的直接链接">​</a></h3>
<p>在idea的运行配置、启动脚本里增加一个java vm的参数配置：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-Djava.library.path=我的项目路径\sherpa-onnx\libs</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>其中libs下放置的就是对应平台的sherpa-onnx动态库，windows下是.dll，linux下是.so。
这个路径和目录结构都是自定义的，可以自己调整。如果是fatjar的运行方式，本目录建议放在jar外，类似于部署环境的本地环境变量/配置文件一般。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="模型及相关文件的位置">模型及相关文件的位置<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#%E6%A8%A1%E5%9E%8B%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%8D%E7%BD%AE" class="hash-link" aria-label="模型及相关文件的位置的直接链接" title="模型及相关文件的位置的直接链接">​</a></h3>
<p>和上文的动态库类似，也是在jar包外的文件目录下，目录组织结构没有限制，和对应的java调用代码中引用的decode/encode等路径保持一致即可。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="各模型的业务用途">各模型的业务用途<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#%E5%90%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%9A%E5%8A%A1%E7%94%A8%E9%80%94" class="hash-link" aria-label="各模型的业务用途的直接链接" title="各模型的业务用途的直接链接">​</a></h2>
<ol>
<li><a href="https://k2-fsa.github.io/sherpa/onnx/kws/index.html" target="_blank" rel="noopener noreferrer">关键词检测</a>。本质是一个非常小的语音识别模型，这里用它来实现语音唤醒（一直监听音频流），类似小爱同学这种。这样就无需使用snowboy了。支持自定义、复数个关键词且不需要重新训练。</li>
<li>语音识别。这里是在成功语音唤醒后，才会从语音唤醒模式切换到语音识别模式，对音频流进行语音识别，进行自己的业务处理。上文选用的<a href="https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english" target="_blank" rel="noopener noreferrer">csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english</a>模型的识别率还可以、支持中英文混合、RTF表现优秀，支持热词。</li>
<li><a href="https://k2-fsa.github.io/sherpa/onnx/hotwords/index.html" target="_blank" rel="noopener noreferrer">热词</a>。使用热词是由于项目中有一些专业性的词汇，不设置热词的默认识别率比较低。热词也是可以自定义、复数个、不需要重新训练。</li>
<li><a href="https://k2-fsa.github.io/sherpa/onnx/tts/index.html" target="_blank" rel="noopener noreferrer">文字转语音</a>。项目中需要文字转语音来作为交互反馈，但只会有中文，所以选择的是仅支持中文的模型。支持多种音色（但没特别标准和合适的音色）。对数字/IP这些的读法并不合适。如果有更合适的模型和方法，请评论分享给我，谢谢。</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="常见问答faqs">常见问答(FAQs)<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#%E5%B8%B8%E8%A7%81%E9%97%AE%E7%AD%94faqs" class="hash-link" aria-label="常见问答(FAQs)的直接链接" title="常见问答(FAQs)的直接链接">​</a></h2>
<p>先看<a href="https://k2-fsa.github.io/sherpa/onnx/faqs/index.html#frequently-asked-question-faqs" target="_blank" rel="noopener noreferrer">官方文档的FAQs</a>。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-given-version-17-is-not-supported-only-version-1-to-10-is-supported-in-this-build">The given version [17] is not supported, only version 1 to 10 is supported in this build。<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#the-given-version-17-is-not-supported-only-version-1-to-10-is-supported-in-this-build" class="hash-link" aria-label="The given version [17] is not supported, only version 1 to 10 is supported in this build。的直接链接" title="The given version [17] is not supported, only version 1 to 10 is supported in this build。的直接链接">​</a></h3>
<p>运行时这个异常不是jdk的问题，jdk&gt;8包括17 21都行，是因为windwos电脑上System32已经有onnxruntime.dll了。
将这个文件的所有者从TrustInstaller变更为管理员后，就可以完全控制了，将其备份，换成从sherpa官方下载jni里用的同名dll。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="java代码少找不到错误">java代码少/找不到/错误。<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#java%E4%BB%A3%E7%A0%81%E5%B0%91%E6%89%BE%E4%B8%8D%E5%88%B0%E9%94%99%E8%AF%AF" class="hash-link" aria-label="java代码少/找不到/错误。的直接链接" title="java代码少/找不到/错误。的直接链接">​</a></h3>
<p>对比：对比官方的java示例代码，对比官方的python示例代码，举一反三和组合拼凑。</p>
<p>联想：从对比的代码联想可能的api，从调试中数据结构联想可能的作用，从源码命名和注释联想可能的用法。比如asr With endpoint detection看源码有rule，猜测其作用和调整尝试。</p>
<p>搜索：比如java的模型配置参数是有层级的（python的配置参数基本是扁平的），分散和隐藏在不同层次的config类里，那就搜索和一层层点进去看内嵌对象。</p>
<p>大模型：使用大模型，尤其是一些copliot如通义灵码等，来更改和优化代码、理解和猜测代码、分析错误原因。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="java的asrkws-实时语音唤醒和识别都正常但加入hotwards的设置后识别出第一句话后就会进程崩溃">Java的asr/kws 实时语音唤醒和识别都正常，但加入hotwards的设置后，识别出第一句话后就会进程崩溃<a href="https://haifengqiu.github.io/blog/sherpa-java-quickstart#java%E7%9A%84asrkws-%E5%AE%9E%E6%97%B6%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%92%8C%E8%AF%86%E5%88%AB%E9%83%BD%E6%AD%A3%E5%B8%B8%E4%BD%86%E5%8A%A0%E5%85%A5hotwards%E7%9A%84%E8%AE%BE%E7%BD%AE%E5%90%8E%E8%AF%86%E5%88%AB%E5%87%BA%E7%AC%AC%E4%B8%80%E5%8F%A5%E8%AF%9D%E5%90%8E%E5%B0%B1%E4%BC%9A%E8%BF%9B%E7%A8%8B%E5%B4%A9%E6%BA%83" class="hash-link" aria-label="Java的asr/kws 实时语音唤醒和识别都正常，但加入hotwards的设置后，识别出第一句话后就会进程崩溃的直接链接" title="Java的asr/kws 实时语音唤醒和识别都正常，但加入hotwards的设置后，识别出第一句话后就会进程崩溃的直接链接">​</a></h3>
<p>多次dump文件后发现都是因为sherpa-onnx-jni.dll的异常：siginfo: EXCEPTION_ACCESS_VIOLATION (0xc0000005), reading address 0x0000000000000070。
Jni使用的下载的jni_sherpa-onnx-v1.10.27（26版本也有同样问题）。asr模型使用的是sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20。跑在Win11 64位笔记本的CPU上（ubuntu也一样有该问题）。</p>
<p>反馈给社区后，很快给出了从master新构建的jni，验证后正常（win11/ubuntu）。官方预计在v1.10.28版本中修复。</p>]]></content>
        <author>
            <name>梓宏</name>
            <uri>https://github.com/haifengqiu</uri>
        </author>
        <category label="sherpa" term="sherpa"/>
        <category label="asr" term="asr"/>
        <category label="tts" term="tts"/>
        <category label="kws" term="kws"/>
    </entry>
</feed>